from flask import Blueprint, request, jsonify, render_template
import jwt
from app import app, db
from app.models import Input, Prediction
import pickle
import pandas as pd
import numpy as np

predict_bp = Blueprint('predict', __name__)

# ëª¨ë¸ ë¡œë“œ
try:
    model = pickle.load(open("model/model_0.83.pkl", "rb"))
except FileNotFoundError:
    raise RuntimeError("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `model/model_0.81.pkl` í™•ì¸ í•„ìš”.")

def get_user_id_from_token():
    """ JWT í† í°ì—ì„œ user_id ì¶”ì¶œ """
    token = request.headers.get("Authorization")
    if not token:
        return None, None  # âœ… ë¹„íšŒì›ì´ë©´ None ë°˜í™˜ (ì—ëŸ¬ X)
    try:
        decoded = jwt.decode(token, app.config["SECRET_KEY"], algorithms=["HS256"])
        return decoded["user_id"], None  # âœ… ë¡œê·¸ì¸í•œ íšŒì›ì´ë©´ user_id ë°˜í™˜
    except jwt.ExpiredSignatureError:
        return None, jsonify({"message": "Token expired"})  # âœ… í† í° ë§Œë£Œ
    except jwt.InvalidTokenError:
        return None, jsonify({"message": "Invalid token"})  # âœ… ì˜ëª»ëœ í† í°

def get_season(month):
    """ ì›”(month)ì— ë”°ë¼ ê³„ì ˆ ë°˜í™˜ """
    if month in [3, 4, 5]:
        return 'ë´„'
    elif month in [6, 7, 8]:
        return 'ì—¬ë¦„'
    elif month in [9, 10, 11]:
        return 'ê°€ì„'
    else:
        return 'ê²¨ìš¸'
    
def preprocess(df):
    try:
        sample = df.copy()
        sample2 = df.copy()

        if sample.empty:
            raise ValueError("âŒ ì…ë ¥ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        # ê²°ì¸¡ ì—¬ë¶€ë¥¼ ì´ì§„ ë³€ìˆ˜ë¡œ ë³€í™˜
        for col in sample2.columns:
            sample2[f'{col}'] = sample2[col].isna().astype(int)
        sample2['ê²°ì¸¡ì¹˜ê°œìˆ˜'] = sample2.sum(axis=1)
        sample['ê²°ì¸¡ì¹˜ê°œìˆ˜'] = sample2['ê²°ì¸¡ì¹˜ê°œìˆ˜']
        
        train_medians = pd.read_csv('./saved/train_medians.csv')

        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        numeric_cols = [col for col in sample.select_dtypes(include=['number']).columns]
        sample[numeric_cols] = sample[numeric_cols].fillna(train_medians)

        # ìŠ¤ì¼€ì¼ëŸ¬ ë° KNN ëª¨ë¸ ë¡œë“œ
        scaler = pickle.load(open("./saved/scaler.pkl", "rb"))
        knn_hc = pickle.load(open("./saved/knn_hc.pkl", "rb"))

        X_test = sample[['ì „ìš©ë©´ì ', 'ë°©ìˆ˜', 'ìš•ì‹¤ìˆ˜']]
        if X_test.isnull().values.any():
            raise ValueError("âŒ ì˜ˆì¸¡ì— í•„ìš”í•œ í•„ìˆ˜ ì»¬ëŸ¼ì— ê²°ì¸¡ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.")

        X_test_scaled = scaler.transform(X_test)
        sample["ë§¤ë¬¼_HC"] = knn_hc.predict(X_test_scaled)

        # ê¸ˆì•¡ ë‹¨ìœ„ ë³€í™˜
        # sample["ë³´ì¦ê¸ˆ"] = sample["ë³´ì¦ê¸ˆ"] / 10000
        # sample["ì›”ì„¸"] = sample["ì›”ì„¸"] / 10000
        sample['ì›”ì„¸+ê´€ë¦¬ë¹„'] = sample['ì›”ì„¸'] + sample['ê´€ë¦¬ë¹„']
        sample['ë³´ì¦ê¸ˆ_ì›”ì„¸ê´€ë¦¬ë¹„_ë¹„ìœ¨'] = sample['ì›”ì„¸+ê´€ë¦¬ë¹„'] / sample['ë³´ì¦ê¸ˆ']
        sample['ì „ìš©ë©´ì _ê°€ê²©_ë¹„ìœ¨'] = sample['ë³´ì¦ê¸ˆ_ì›”ì„¸ê´€ë¦¬ë¹„_ë¹„ìœ¨'] / sample['ì „ìš©ë©´ì ']

        scaler2 = pickle.load(open("./saved/scaler2.pkl", "rb"))
        knn_kmedoids = pickle.load(open("./saved/knn_kmedoids.pkl", "rb"))

        X_test2 = sample[['ë§¤ë¬¼_HC', 'ì „ìš©ë©´ì _ê°€ê²©_ë¹„ìœ¨', 'ë³´ì¦ê¸ˆ_ì›”ì„¸ê´€ë¦¬ë¹„_ë¹„ìœ¨']]
        X_test_scaled2 = scaler2.transform(X_test2)
        sample["ì§€ì—­_KMedoids"] = knn_kmedoids.predict(X_test_scaled2)

        sample['ê²Œì¬ì¼'] = pd.to_datetime(sample['ê²Œì¬ì¼'], errors='coerce')
        sample['ê³„ì ˆ'] = sample['ê²Œì¬ì¼'].dt.month.apply(get_season)

        date_max = pickle.load(open("./saved/date_max.pkl", "rb"))
        sample['ë§¤ë¬¼_ë“±ë¡_ê²½ê³¼ì¼'] = (date_max - sample['ê²Œì¬ì¼']).dt.days

        sample = pd.get_dummies(sample, columns=['ë§¤ë¬¼í™•ì¸ë°©ì‹', 'ë°©í–¥', 'ì£¼ì°¨ê°€ëŠ¥ì—¬ë¶€', 'ê³„ì ˆ'], drop_first=True)

        return sample
    except Exception as e:
        raise ValueError(f"ğŸš¨ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def make_prediction(input_data):
    try:
        df = pd.DataFrame([input_data])
        preprocessed_df = preprocess(df)
        prediction = model.predict(preprocessed_df)
        pred_proba = model.predict_proba(preprocessed_df)
        correct_probs = pred_proba[np.arange(len(prediction)), prediction]
        percent_probs_mean = (correct_probs * 100).round(1).mean()
        return prediction, percent_probs_mean
    except Exception as e:
        raise ValueError(f"ğŸš¨ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

#predict urlë¡œ POST ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ predict()ë©”ì„œë“œë¥¼ ìˆ˜í–‰í•˜ê² ë‹¤ëŠ” ì˜ë¯¸
@predict_bp.route("/predict", methods=["POST"])
def predict():
    """ JSON ì…ë ¥ì„ ë°›ì•„ì„œ ë‹¨ì¼ ì˜ˆì¸¡ ìˆ˜í–‰ """
    user_id, error_response = get_user_id_from_token()
    if error_response:
        return error_response  # ì¸ì¦ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜
    
    data = request.json

    try:
        prediction_result, percent_probs_mean = make_prediction(data)
    except ValueError as e:
        return jsonify({"error": str(e)}), 400

    new_input = Input(user_id=user_id, input_data=data)
    db.session.add(new_input)
    db.session.commit()

    new_prediction = Prediction(input_id=new_input.id, 
                                prediction_result=prediction_result, 
                                percent_probs_mean=percent_probs_mean)
    db.session.add(new_prediction)
    db.session.commit()

    return jsonify({"prediction": prediction_result, "pred_proba": percent_probs_mean})

@predict_bp.route("/predict/file", methods=["POST"])
def predict_file():
    """ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë‹¤ì¤‘ ì˜ˆì¸¡ ìˆ˜í–‰ """
    ##############################################
    user_id, error_response = get_user_id_from_token()
    if error_response:
        return error_response
    
    # âœ… íŒŒì¼ ì—…ë¡œë“œ ì²´í¬ ë¡œì§ ì¶”ê°€
    if "file" not in request.files:
        return jsonify({"error": "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

    file = request.files.get("file")
    
    if file is None:
        return jsonify({"error": "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

    if file.filename == "":
        return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

    if not file.filename.endswith(".csv"):
        return jsonify({"error": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."}), 400
    
    try:
        df = pd.read_csv(file)

        # ë°ì´í„° ì „ì²˜ë¦¬ ìˆ˜í–‰
        preprocessed_df = preprocess(df)

        predictions = model.predict(preprocessed_df)
        pred_proba = model.predict_proba(preprocessed_df)
        correct_probs = pred_proba[np.arange(len(predictions)), predictions]
        confidence_scores = (correct_probs * 100).round(1)

        prediction_labels = ["í—ˆìœ„ë§¤ë¬¼ì´ ì•„ë‹™ë‹ˆë‹¤" if pred == 0 else "í—ˆìœ„ë§¤ë¬¼ì…ë‹ˆë‹¤" for pred in predictions]

        result_df = df.copy()
        result_df["ì˜ˆì¸¡ ê²°ê³¼"] = prediction_labels
        result_df["ì‹ ë¢°ë„ (%)"] = confidence_scores

        result_html = result_df.to_html(classes="table table-striped", index=False)

        return render_template("result.html", table=result_html)

    except Exception as e:
        return jsonify({"error": "íŒŒì¼ ì˜ˆì¸¡ ì‹¤íŒ¨", "message": str(e)}), 400
